{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Token_to_BoG_vector.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"GMHG4KYrG9F6","colab_type":"code","outputId":"3fbbb1e6-9878-4b46-a472-c20fd02c2c2d","executionInfo":{"status":"ok","timestamp":1584826284282,"user_tz":240,"elapsed":53096,"user":{"displayName":"Xi Zheng","photoUrl":"","userId":"02442488239187981395"}},"colab":{"base_uri":"https://localhost:8080/","height":222}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 144542 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.18-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PsHEFyqCHHPf","colab_type":"code","colab":{}},"source":["from tqdm import tqdm\n","from google.colab import drive\n","import numpy as np\n","import pandas as pd \n","from pandas import DataFrame\n","import spacy\n","import operator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"avCRSaWVHj9L","colab_type":"code","outputId":"369e6542-c516-4112-c139-2578ba2c71e8","executionInfo":{"status":"ok","timestamp":1584826312795,"user_tz":240,"elapsed":21493,"user":{"displayName":"Xi Zheng","photoUrl":"","userId":"02442488239187981395"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pJRTE3pvHngL","colab_type":"code","colab":{}},"source":["# Read the file that contain Title token and Description token\n","df_train_X = pd.read_csv(\"gdrive/My Drive/5500/job-salary-prediction/Train_X_modified.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9eu8y_4HxAT","colab_type":"code","outputId":"7f15f2cd-401f-4aa8-c5c4-e95473502101","executionInfo":{"status":"ok","timestamp":1584826329496,"user_tz":240,"elapsed":4010,"user":{"displayName":"Xi Zheng","photoUrl":"","userId":"02442488239187981395"}},"colab":{"base_uri":"https://localhost:8080/","height":976}},"source":["df_train_X"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Title</th>\n","      <th>Token Title</th>\n","      <th>FullDescription</th>\n","      <th>Token Description</th>\n","      <th>LocationNormalized</th>\n","      <th>ContractType</th>\n","      <th>ContractTime</th>\n","      <th>Company</th>\n","      <th>Category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Engineering Systems Analyst</td>\n","      <td>['engineering', 'systems', 'analyst']</td>\n","      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n","      <td>['engineering', 'systems', 'analyst', 'dorking...</td>\n","      <td>Dorking</td>\n","      <td>NaN</td>\n","      <td>permanent</td>\n","      <td>Gregory Martin International</td>\n","      <td>Engineering Jobs</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Stress Engineer Glasgow</td>\n","      <td>['stress', 'engineer', 'glasgow']</td>\n","      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n","      <td>['stress', 'engineer', 'glasgow', 'salary', 'c...</td>\n","      <td>Glasgow</td>\n","      <td>NaN</td>\n","      <td>permanent</td>\n","      <td>Gregory Martin International</td>\n","      <td>Engineering Jobs</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Modelling and simulation analyst</td>\n","      <td>['modelling', 'simulation', 'analyst']</td>\n","      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n","      <td>['mathematical', 'modeller', 'simulation', 'an...</td>\n","      <td>Hampshire</td>\n","      <td>NaN</td>\n","      <td>permanent</td>\n","      <td>Gregory Martin International</td>\n","      <td>Engineering Jobs</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n","      <td>['engineering', 'systems', 'analyst', 'mathema...</td>\n","      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n","      <td>['engineering', 'systems', 'analyst', 'mathema...</td>\n","      <td>Surrey</td>\n","      <td>NaN</td>\n","      <td>permanent</td>\n","      <td>Gregory Martin International</td>\n","      <td>Engineering Jobs</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Pioneer, Miser Engineering Systems Analyst</td>\n","      <td>['pioneer', 'miser', 'engineering', 'systems',...</td>\n","      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n","      <td>['pioneer', 'miser', ' ', 'engineering', 'syst...</td>\n","      <td>Surrey</td>\n","      <td>NaN</td>\n","      <td>permanent</td>\n","      <td>Gregory Martin International</td>\n","      <td>Engineering Jobs</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>244763</th>\n","      <td>244763</td>\n","      <td>TEACHER OF SCIENCE</td>\n","      <td>['teacher', 'science']</td>\n","      <td>Position: Qualified Teacher Subject/Specialism...</td>\n","      <td>['position', 'qualified', 'teacher', 'subject'...</td>\n","      <td>Swindon</td>\n","      <td>NaN</td>\n","      <td>contract</td>\n","      <td>NaN</td>\n","      <td>Teaching Jobs</td>\n","    </tr>\n","    <tr>\n","      <th>244764</th>\n","      <td>244764</td>\n","      <td>TEACHER OF BUSINESS STUDIES AND ICT</td>\n","      <td>['teacher', 'business', 'studies', 'ict']</td>\n","      <td>Position: Qualified Teacher or NQT Subject/Spe...</td>\n","      <td>['position', 'qualified', 'teacher', 'nqt', 's...</td>\n","      <td>Swindon</td>\n","      <td>NaN</td>\n","      <td>contract</td>\n","      <td>NaN</td>\n","      <td>Teaching Jobs</td>\n","    </tr>\n","    <tr>\n","      <th>244765</th>\n","      <td>244765</td>\n","      <td>ENGLISH TEACHER</td>\n","      <td>['english', 'teacher']</td>\n","      <td>Position: Qualified Teacher Subject/Specialism...</td>\n","      <td>['position', 'qualified', 'teacher', 'subject'...</td>\n","      <td>Swindon</td>\n","      <td>NaN</td>\n","      <td>contract</td>\n","      <td>NaN</td>\n","      <td>Teaching Jobs</td>\n","    </tr>\n","    <tr>\n","      <th>244766</th>\n","      <td>244766</td>\n","      <td>SUPPLY TEACHERS</td>\n","      <td>['supply', 'teacher']</td>\n","      <td>Position: Qualified Teacher Subject/Specialism...</td>\n","      <td>['position', 'qualified', 'teacher', 'subject'...</td>\n","      <td>Wiltshire</td>\n","      <td>NaN</td>\n","      <td>contract</td>\n","      <td>NaN</td>\n","      <td>Teaching Jobs</td>\n","    </tr>\n","    <tr>\n","      <th>244767</th>\n","      <td>244767</td>\n","      <td>Accountant</td>\n","      <td>['accountant']</td>\n","      <td>This entrepreneurial and growing private equit...</td>\n","      <td>['entrepreneurial', 'grow', 'private', 'equity...</td>\n","      <td>Hitchin</td>\n","      <td>NaN</td>\n","      <td>permanent</td>\n","      <td>NaN</td>\n","      <td>Teaching Jobs</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>244768 rows × 10 columns</p>\n","</div>"],"text/plain":["        Unnamed: 0  ...          Category\n","0                0  ...  Engineering Jobs\n","1                1  ...  Engineering Jobs\n","2                2  ...  Engineering Jobs\n","3                3  ...  Engineering Jobs\n","4                4  ...  Engineering Jobs\n","...            ...  ...               ...\n","244763      244763  ...     Teaching Jobs\n","244764      244764  ...     Teaching Jobs\n","244765      244765  ...     Teaching Jobs\n","244766      244766  ...     Teaching Jobs\n","244767      244767  ...     Teaching Jobs\n","\n","[244768 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"nfXCRPRtH0bh","colab_type":"code","colab":{}},"source":["# Make a dictionary, contain the frequency of each words\n","def list_to_count_dic(Text_List):\n","  vol_dic = {}\n","  for i in tqdm(Text_List):\n","    spited_i=i[1:-1].split(', ')\n","    for j in spited_i:\n","      if j[1:-1] != ' ':\n","        if j[1:-1] not in vol_dic:\n","          vol_dic[j[1:-1]] = 1\n","        else:\n","          vol_dic[j[1:-1]] += 1\n","  \n","  return vol_dic\n","\n","# Reorder the dictionary above from most frequent word to least frequent word, and then take a \"vol_size\" number of most frequent words as the vocabulary\n","def build_vocabulary(dic, vol_size):\n","  sorted_dic = dict(sorted(dic.items(), key=operator.itemgetter(1),reverse=True))\n","  vol = list(sorted_dic)[:vol_size]\n","  return vol"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6pwePNSHIBft","colab_type":"code","outputId":"118eaa9b-a9f2-46fb-b4c8-39939148c8e5","executionInfo":{"status":"ok","timestamp":1584826355492,"user_tz":240,"elapsed":19503,"user":{"displayName":"Xi Zheng","photoUrl":"","userId":"02442488239187981395"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Build volcabulary for description\n","description_dic = list_to_count_dic(df_train_X[\"Token Description\"])\n","train_description_vol = build_vocabulary(description_dic, 2000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 244768/244768 [00:18<00:00, 13029.93it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xN7Xc34V__0H","colab_type":"code","colab":{}},"source":["# Build volcabulary for title\n","title_dic = list_to_count_dic(df_train_X[\"Token Title\"])\n","train_title_vol = build_vocabulary(title_dic, 200)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tvSW4dWZPMAF","colab_type":"text"},"source":["Bag of Words: representation of text that describes the occurrence of words within a document.\n","\n","Example:\n","\n","Vocabulary: [\"today\", \"sunny\", \"rainy\"]\n","\n","text: Today is a sunny day. -> vector: [1, 1, 0]"]},{"cell_type":"code","metadata":{"id":"OidiEJxyIQ1z","colab_type":"code","colab":{}},"source":["# Transform each text token to a bag-of-words vector\n","\n","def token_to_bag_of_words_vector(text_token, vol):\n","  vec = []\n","  spited_token=text_token[1:-1].split(', ')\n","  new_token = []\n","  for j in spited_token:\n","    if j[1:-1] != ' ':\n","      new_token.append(j[1:-1])\n","  #print(new_token)\n","  for i in vol:\n","    if i in new_token:\n","      #print(\"yes\")\n","      vec.append(1)\n","    else:\n","      vec.append(0)\n","  return vec"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_WlrC8H4LYsT","colab_type":"code","colab":{}},"source":["# Convert the array of title token to Bag of Words vector\n","train_title_BoG = []\n","for i in tqdm(df_train_X[\"Token Title\"]):\n","  token_vec = token_to_bag_of_words_vector(i,train_title_vol)\n","  train_title_BoG.append(token_vec)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fMU1MSdwPZue","colab_type":"code","colab":{}},"source":["# Convert the array of description token to Bag of Words vector\n","train_description_BoG = []\n","for i in tqdm(df_train_X[\"Token Description\"]):\n","  token_vec = token_to_bag_of_words_vector(i,train_description_vol)\n","  train_description_BoG.append(token_vec)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"13LvQngVBh1G","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}